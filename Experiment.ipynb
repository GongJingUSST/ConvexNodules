{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from support.datatools import *\n",
    "from support.paths import PATH\n",
    "from objectives.logist import objective\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from cvxopt import matrix, solvers\n",
    "from numpy import logspace\n",
    "\n",
    "# %pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport objectives.logist\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport support.datatools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_FOLD = str(2)\n",
    "VALID_FOLD = str(3)\n",
    "SHIFT = 2\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCH = 20\n",
    "OVERSAMPLING = .7\n",
    "UNDERSAMPLING = 8\n",
    "LOWER = -1000\n",
    "UPPER = 400\n",
    "IN_SHAPE = (1, 22, 22)\n",
    "WEIGHTS = '/home/a.dobrenkii/Projects/Kaggle/DataScienceBowl2K17/data/WEIGHTS/'\n",
    "CPU = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train, valid, test = extract_paths(VALID_FOLD, TEST_FOLD)\n",
    "train_generator = batch_generator(train,\n",
    "                                  batch_size=BATCH_SIZE, \n",
    "                                  in_shape=IN_SHAPE,\n",
    "                                  lower=LOWER,\n",
    "                                  upper=UPPER,\n",
    "                                  shift=SHIFT,\n",
    "                                  undersampling=UNDERSAMPLING,\n",
    "                                  oversampling=OVERSAMPLING,\n",
    "                                  CPU=CPU)\n",
    "\n",
    "test_generator = batch_generator(new_test,\n",
    "                                 batch_size=BATCH_SIZE, \n",
    "                                 in_shape=IN_SHAPE,\n",
    "                                 lower=LOWER,\n",
    "                                 upper=UPPER,\n",
    "                                 shift=0, \n",
    "                                 undersampling=0,\n",
    "                                 oversampling=1,\n",
    "                                 CPU=CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_test = manipulate_samples(test.tolist(), UNDERSAMPLING, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $lr == 1/L$  \n",
    "Define prox-function $d(\\vec{x}) \\equiv ||\\, \\vec{x}\\, ||^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class optimizer:\n",
    "    def __init__(self, method, objective, lr=.01):\n",
    "        self.methods = {\n",
    "            \"SGD\": self.SGD,\n",
    "            \"FGD\": self.FGD,\n",
    "            \"L_BFGS\": self.L_BFGS,\n",
    "            \"VL_BFGS\": self.VL_BFGS\n",
    "        }\n",
    "\n",
    "        message = \"The method param should match one of: \" + ', '.join(self.methods.keys())\n",
    "        assert method in self.methods.keys(), message\n",
    "        \n",
    "        self.method =  self.methods[method]\n",
    "        self.objective = objective\n",
    "        self.grads_hist = 0\n",
    "        self.i = 0\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "    def iteration_prior(self):\n",
    "        self.i += 1\n",
    "        \n",
    "        \n",
    "    def __call__(self, X, y):\n",
    "        self.iteration_prior()\n",
    "        self.method(X, y)\n",
    "\n",
    "        \n",
    "    def SGD(self, X, y):\n",
    "        self.objective.w -= self.lr * self.objective.gradf(X, y)\n",
    "    \n",
    "    \n",
    "    def FGD(self, X, y):\n",
    "        grad_i = self.objective.gradf(X, y)\n",
    "        # Here lr == 1/L\n",
    "        y_i = self.objective.w - self.lr * grad_i\n",
    "        # Define prox-function d(\\vec{x}) \\equiv || \\vec{x} ||^{2}\n",
    "        self.grads_hist += (self.i + 1) / 2 * grad_i\n",
    "        z_i = - self.lr * self.grads_hist\n",
    "        self.objective.w = 2. /(self.i + 3.) * z_i + (self.i + 1.) / (self.i + 3.) * y_i\n",
    "    \n",
    "    \n",
    "    def VL_BFGS(self, X, y):\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    def VL_BFGS(self, X, y):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logloss(X, y, objective=None):\n",
    "    if objective is not None:\n",
    "        return np.log(1 + np.exp(np.matmul(objective(X), y)))\n",
    "    return np.log(1 + np.exp(np.matmul(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LR:\n",
    "    def __init__(self, objective, optimizer, loss):\n",
    "        self.losses = {\n",
    "            \"logloss\": logloss\n",
    "        }\n",
    "\n",
    "        message = \"The loss param should match one of: \" + ', '.join(self.losses.keys())\n",
    "        assert loss in self.losses.keys(), message\n",
    "        self.loss =  self.losses[loss]\n",
    "        self.loss_name = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.objective = objective\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание вероятности принадлежности объекта к классу 1.\n",
    "        Возвращает np.array размера (N,) чисел в отрезке от 0 до 1.\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :return: numpy.array размера  (N,), dtype = np.int\n",
    "        \"\"\"\n",
    "        return special.expit(objective(X))\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание класса для объекта.\n",
    "        Возвращает np.array размера (N,) элементов 1 или -1.\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :return:  numpy.array размера  (N,), dtype = np.int\n",
    "        \"\"\"\n",
    "        return self.predict_proba(X) > .5\n",
    "    \n",
    "    \n",
    "    def evaluate_generator(self, data_generator, nb_iterations):\n",
    "        objective_loss = list()\n",
    "        addition_loss = list()\n",
    "        for i in tqdm(range(nb_iterations)):\n",
    "            X, y = next(data_generator)\n",
    "            objective_loss.append(self.objective.lossf(X, y))\n",
    "            addition_loss.append(self.loss(self.objective(X), y))\n",
    "            clear_output()\n",
    "        return objective_loss, addition_loss\n",
    "    \n",
    "    \n",
    "    def predict_generator(self, data_generator, nb_iterations):\n",
    "        predicted = list()\n",
    "        for i in tqdm(range(nb_iterations)):\n",
    "            X, y = next(data_generator)\n",
    "            predicted += objective(X).tolist()\n",
    "            clear_output()\n",
    "        return predicted\n",
    "        \n",
    "\n",
    "    def fit_generator(self, train_data, \n",
    "                      nb_iterations, nb_epoch, \n",
    "                      validation_data=None, \n",
    "                      nb_val_iterations=None,\n",
    "                      verbose=0\n",
    "                     ):\n",
    "        \"\"\"\n",
    "        Обучение логистической регрессии.\n",
    "        Настраивает self.w коэффициенты модели.\n",
    "        Если self.verbose == True, то выводите значение \n",
    "        функции потерь на итерациях метода оптимизации. \n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :param y: numpy.array размера  (N,), dtype = np.int\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        history = {\n",
    "            'objective_loss': [],\n",
    "            'addition_loss': [],\n",
    "            'objective_val_loss': [-1],\n",
    "            'addition_val_loss': [-1]\n",
    "        }\n",
    "        \n",
    "        for epoch in tqdm(range(nb_epoch)):\n",
    "            objective_loss = list()\n",
    "            addition_loss = list()\n",
    "            \n",
    "            for i in tqdm(range(nb_iterations)):\n",
    "                X, y = next(train_data)\n",
    "                if verbose:\n",
    "                    objective_loss.append(self.objective.lossf(X, y))\n",
    "                    addition_loss.append(self.loss(self.objective(X), y))\n",
    "                    history['objective_loss'].append(mean(objective_loss))\n",
    "                    history['addition_loss'].append(mean(addition_loss))\n",
    "                    clear_output()\n",
    "                    print(\"Epoch \" + str(epoch) + \"/\" + str(nb_epoch)) \n",
    "                    if validation_data is not None:\n",
    "                        print(\"Current objective val loss is \" + str(history['objective_val_loss'][-1]))\n",
    "                        print(\"Current val \" + self.loss_name + \" is \" + str(history['addition_val_loss'][-1]))\n",
    "                    print(\"Iteration \" + str(i) + \".\")\n",
    "                    print(\"Current objective loss is \" + str(history['objective_loss'][-1]))\n",
    "                    print(\"Current \" + self.loss_name + \" is \" + str(history['objective_loss'][-1]))\n",
    "                self.w = self.optimizer(X, y)  \n",
    "            \n",
    "            if validation_data is not None:\n",
    "                objective_val_loss, addition_val_loss = \\\n",
    "                    self.evaluate_generator(validation_data, nb_val_iterations)\n",
    "                history['objective_val_loss'].append(mean(objective_val_loss))\n",
    "                history['addition_val_loss'].append(mean(addition_val_loss))\n",
    "        return  history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objf = objective(dim=484, w=None, l1=1e-4, l2=1e-4)\n",
    "optf = optimizer('FGD', objf)\n",
    "clf = LR(objf, optf, 'logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 43/43 [00:23<00:00,  1.68it/s]\u001b[A\n",
      "100%|██████████| 10/10 [45:09<00:00, 270.59s/it]\n"
     ]
    }
   ],
   "source": [
    "history = clf.fit_generator(train_generator, \n",
    "                            10 * len(new_test) // BATCH_SIZE, \n",
    "                            nb_epoch=10, \n",
    "                            validation_data=test_generator, \n",
    "                            nb_val_iterations=len(new_test) // BATCH_SIZE, \n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 50.879387378644907, 43.106004618714493, 201.36140271658786, 304.84066715535374, 140.51239266775499, 59.535261077028537, 56.17323863503794, inf, inf, inf]\n",
      "[-1, 50.88022443540077, 43.106718866102433, 201.3675230412604, 304.85181339078321, 140.51770488516124, 59.537895772182871, 56.176272972828023, inf, inf, inf]\n"
     ]
    }
   ],
   "source": [
    "print(history['addition_val_loss'])\n",
    "print(history['objective_val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55800it [05:30, 169.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# test_labels = array(['nodule' in i.lower() for i in test])\n",
    "# table = pickle.load(open(join(WEIGHTS, 'table_nodules'), 'rb'))\n",
    "df = pd.DataFrame(columns=['seriesuid', 'coordX', \n",
    "                           'coordY', 'coordZ', \n",
    "                           'class', 'probability'])\n",
    "for uid, val in tqdm(zip(test, predicted)):\n",
    "    table[basename(uid)[:-4]][0]['probability'] = val\n",
    "    df = df.append(table[basename(uid)[:-4]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/a.dobrenkii/Projects/Kaggle/DataScienceBowl2K17/I/LungCancerDetection/support/evaluationScript/annotations/seriesuids_log.csv'\n",
    "seriesuid = pd.Series(unique(df.seriesuid.values))\n",
    "seriesuid.to_csv(path, index=False)\n",
    "path = '/home/a.dobrenkii/Projects/Kaggle/DataScienceBowl2K17/I/LungCancerDetection/support/evaluationScript/exampleFiles/submission/sampleSubmission_log.csv'\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/a.dobrenkii/Projects/Kaggle/DataScienceBowl2K17/I/LungCancerDetection/support/evaluationScript/annotations/annotations.csv'\n",
    "annotations = pd.read_csv(path)\n",
    "annotations = annotations[annotations.seriesuid.isin(seriesuid)]\n",
    "path = '/home/a.dobrenkii/Projects/Kaggle/DataScienceBowl2K17/I/LungCancerDetection/support/evaluationScript/annotations/annotations_log.csv'\n",
    "annotations.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1934/1934 [09:24<00:00,  3.67it/s]\u001b[A\n",
      "100%|██████████| 10/10 [1:32:22<00:00, 558.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Iteration 1933. Current loss is 0.0612552275888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LR at 0x7f6a30298438>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit_generator(train_generator, len(train) // (8 * BATCH_SIZE), 10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
